{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "527f8e31",
   "metadata": {},
   "source": [
    "Source: https://python.langchain.com/docs/tutorials/llm_chain/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3515867",
   "metadata": {},
   "source": [
    "- get your llm api key\n",
    "- Use Groq - its free\n",
    "- save it in .env file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a01dc67e",
   "metadata": {},
   "source": [
    "Also do these steps in .env\n",
    "\n",
    "LANGSMITH_TRACING=\"true\"\n",
    "LANGSMITH_API_KEY=\"...\"\n",
    "LANGSMITH_PROJECT=\"default\" # or any other project name"
   ]
  },
  {
   "cell_type": "code",
   "id": "682c4c87",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-29T19:13:19.271382Z",
     "start_time": "2025-09-29T19:13:19.259904Z"
    }
   },
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "id": "afe84af3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-26T09:43:32.777636Z",
     "start_time": "2025-08-26T09:43:32.776138Z"
    }
   },
   "source": [
    "# !pip install -qU \"langchain[groq]\""
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "id": "a0e461e5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-29T19:14:46.814182Z",
     "start_time": "2025-09-29T19:14:46.795643Z"
    }
   },
   "source": [
    "from langchain.chat_models import init_chat_model\n",
    "\n",
    "model = init_chat_model(\"llama-3.1-8b-instant\", model_provider=\"groq\")"
   ],
   "outputs": [],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "id": "a6f93f75",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-29T19:14:47.809736Z",
     "start_time": "2025-09-29T19:14:47.648504Z"
    }
   },
   "source": [
    "# A simple model call\n",
    "\n",
    "model.invoke(\"Whats up?\")"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Not much. How can I assist you today?', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 11, 'prompt_tokens': 38, 'total_tokens': 49, 'completion_time': 0.014333703, 'prompt_time': 0.002122748, 'queue_time': 0.049566492, 'total_time': 0.016456451}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_90c2e79dab', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--94949243-5e6d-45c5-b7bc-7fd994a4a2dd-0', usage_metadata={'input_tokens': 38, 'output_tokens': 11, 'total_tokens': 49})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "cell_type": "markdown",
   "id": "42416cbd",
   "metadata": {},
   "source": [
    "[Exercise] Play along. Give bigger and bigger prompts"
   ]
  },
  {
   "cell_type": "code",
   "id": "da2738af",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-29T19:14:49.980451Z",
     "start_time": "2025-09-29T19:14:49.621940Z"
    }
   },
   "source": [
    "model.invoke(\"Who are you?\")"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"I'm an artificial intelligence model known as a large language model (LLM) or conversational AI. I was created to provide information, answer questions, and engage in conversations with users like you. I'm a computer program designed to simulate human-like conversations and understand the context of the topics we discuss.\\n\\nI don't have a personal identity or emotions like humans do, but I'm designed to be helpful and assist with a wide range of topics, from science and history to entertainment and culture. I can also generate text, respond to questions, and even create content like stories or dialogues.\\n\\nI'm constantly learning and improving my abilities through machine learning algorithms and large datasets of text. This allows me to stay up-to-date with the latest knowledge and provide accurate and informative responses to your questions.\\n\\nSo, what would you like to talk about? I'm here to help and provide information on any topic you're interested in!\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 186, 'prompt_tokens': 39, 'total_tokens': 225, 'completion_time': 0.24894057, 'prompt_time': 0.002114206, 'queue_time': 0.051967964, 'total_time': 0.251054776}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_50a6be1b6f', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--35c87911-68ad-468a-a3c2-87045d83a328-0', usage_metadata={'input_tokens': 39, 'output_tokens': 186, 'total_tokens': 225})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "id": "a7f4578d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-29T19:14:52.313834Z",
     "start_time": "2025-09-29T19:14:51.786129Z"
    }
   },
   "source": [
    "response = model.invoke(\"\"\" Make a program in python to display a random number each time you use it. \"\"\")\n",
    "\n",
    "response"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='**Random Number Generator Program in Python**\\n\\nHere\\'s a simple program in Python that generates a random number each time you run it:\\n```python\\nimport random\\n\\ndef get_random_number():\\n    \"\"\"\\n    Generate a random integer between 1 and 100.\\n    \"\"\"\\n    return random.randint(1, 100)\\n\\ndef main():\\n    print(\"Random Number Generator\")\\n    print(\"------------------------\")\\n    \\n    while True:\\n        print(\"Your random number is:\", get_random_number())\\n        response = input(\"Do you want to generate another number? (y/n): \")\\n        if response.lower() != \\'y\\':\\n            break\\n\\nif __name__ == \"__main__\":\\n    main()\\n```\\n**How it works**\\n\\n1. Import the `random` module, which provides functions for generating random numbers.\\n2. Define a function `get_random_number()` that uses `random.randint()` to generate a random integer between 1 and 100.\\n3. In the `main()` function, print a welcome message and enter an infinite loop.\\n4. In each iteration of the loop, print the random number generated by `get_random_number()`.\\n5. Prompt the user to enter \\'y\\' to generate another number or \\'n\\' to exit.\\n6. If the user enters anything other than \\'y\\', break out of the loop and exit the program.\\n\\n**Example Output**\\n```\\nRandom Number Generator\\n------------------------\\nYour random number is: 42\\nDo you want to generate another number? (y/n): y\\nYour random number is: 91\\nDo you want to generate another number? (y/n): n\\n```\\nRun this program to generate a random number each time you run it!', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 344, 'prompt_tokens': 52, 'total_tokens': 396, 'completion_time': 0.396029718, 'prompt_time': 0.002397572, 'queue_time': 0.051698308, 'total_time': 0.39842729}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_a7a2f9abbf', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--31b66c04-037c-4652-9192-95e5c6ef58c6-0', usage_metadata={'input_tokens': 52, 'output_tokens': 344, 'total_tokens': 396})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "id": "17c8c30d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-29T19:14:54.097357Z",
     "start_time": "2025-09-29T19:14:54.092244Z"
    }
   },
   "source": [
    "print(response.content)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Random Number Generator Program in Python**\n",
      "\n",
      "Here's a simple program in Python that generates a random number each time you run it:\n",
      "```python\n",
      "import random\n",
      "\n",
      "def get_random_number():\n",
      "    \"\"\"\n",
      "    Generate a random integer between 1 and 100.\n",
      "    \"\"\"\n",
      "    return random.randint(1, 100)\n",
      "\n",
      "def main():\n",
      "    print(\"Random Number Generator\")\n",
      "    print(\"------------------------\")\n",
      "    \n",
      "    while True:\n",
      "        print(\"Your random number is:\", get_random_number())\n",
      "        response = input(\"Do you want to generate another number? (y/n): \")\n",
      "        if response.lower() != 'y':\n",
      "            break\n",
      "\n",
      "if __name__ == \"__main__\":\n",
      "    main()\n",
      "```\n",
      "**How it works**\n",
      "\n",
      "1. Import the `random` module, which provides functions for generating random numbers.\n",
      "2. Define a function `get_random_number()` that uses `random.randint()` to generate a random integer between 1 and 100.\n",
      "3. In the `main()` function, print a welcome message and enter an infinite loop.\n",
      "4. In each iteration of the loop, print the random number generated by `get_random_number()`.\n",
      "5. Prompt the user to enter 'y' to generate another number or 'n' to exit.\n",
      "6. If the user enters anything other than 'y', break out of the loop and exit the program.\n",
      "\n",
      "**Example Output**\n",
      "```\n",
      "Random Number Generator\n",
      "------------------------\n",
      "Your random number is: 42\n",
      "Do you want to generate another number? (y/n): y\n",
      "Your random number is: 91\n",
      "Do you want to generate another number? (y/n): n\n",
      "```\n",
      "Run this program to generate a random number each time you run it!\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "id": "8b215da3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-29T19:17:42.435990Z",
     "start_time": "2025-09-29T19:17:42.115599Z"
    }
   },
   "source": [
    "# invoking to build a converstation style call\n",
    "\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "\n",
    "messages = [\n",
    "    SystemMessage(\"Translate from english to Binary and then to Morse\"), # try punjabi, or any other Indian language\n",
    "    HumanMessage(\"hi!\"),\n",
    "]\n",
    "\n",
    "model.invoke(messages)"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='To translate \"hi\" from English to binary, we first need to convert each letter into its ASCII code and then convert that code into binary.\\n\\n- \\'h\\' is represented by ASCII code 104, which is 01101000 in binary.\\n- \\'i\\' is represented by ASCII code 105, which is 01101001 in binary.\\n\\nSo, \"hi\" in binary is 01101000 01101001.\\n\\nNow, let\\'s convert \"hi\" from binary to Morse code.\\n\\n- \\'h\\' in Morse code is ....\\n- \\'i\\' in Morse code is ..\\n\\nSo, \"hi\" in Morse code is .... ..', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 133, 'prompt_tokens': 46, 'total_tokens': 179, 'completion_time': 0.186718738, 'prompt_time': 0.002743109, 'queue_time': 0.050984491, 'total_time': 0.189461847}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_50a6be1b6f', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--2cdc7144-4bd7-48ca-8f8c-390335e6eab7-0', usage_metadata={'input_tokens': 46, 'output_tokens': 133, 'total_tokens': 179})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-29T19:17:43.720223Z",
     "start_time": "2025-09-29T19:17:43.252780Z"
    }
   },
   "cell_type": "code",
   "source": "print(model.invoke(messages).content)",
   "id": "f3dcaf0673fb646a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To translate \"hi\" to binary and then to Morse code, I'll do the following steps:\n",
      "\n",
      "**1. Translate \"hi\" to binary:**\n",
      "\n",
      "To convert text to binary, we need to convert each character to its corresponding binary code using ASCII values.\n",
      "\n",
      "- 'h' in ASCII is 104\n",
      "- 'i' in ASCII is 105\n",
      "\n",
      "Converting these to binary:\n",
      "\n",
      "- 104 in binary is 1101000\n",
      "- 105 in binary is 1101001\n",
      "\n",
      "So, \"hi\" in binary is: 1101000 1101001\n",
      "\n",
      "**2. Translate binary to Morse code:**\n",
      "\n",
      "To convert binary to Morse code, we need to convert each binary digit (0 or 1) to its corresponding Morse code symbol.\n",
      "\n",
      "- 0 in binary is represented as '·' (dot) in Morse code\n",
      "- 1 in binary is represented as '-' (dash) in Morse code\n",
      "\n",
      "Using this conversion, we get:\n",
      "\n",
      "- 1101000 in Morse code is: -····\n",
      "- 1101001 in Morse code is: -·····\n",
      "\n",
      "So, \"hi\" in Morse code is: -···· -·····\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "cell_type": "code",
   "id": "9efe5fb2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-29T19:16:35.961507Z",
     "start_time": "2025-09-29T19:16:35.742175Z"
    }
   },
   "source": [
    "messages = [\n",
    "    SystemMessage(\"Generate python code for given tasks. Do not include comments. Minimize the number of lines\"),\n",
    "    HumanMessage(\"Find the sum of all elements in a matrix 3x3 with random numbers\"),\n",
    "]\n",
    "\n",
    "response = model.invoke(messages)\n",
    "\n",
    "response"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='```python\\nimport numpy as np\\nimport random\\n\\nmatrix = np.array([[random.randint(0, 100) for _ in range(3)] for _ in range(3)])\\nprint(matrix)\\nprint(np.sum(matrix))\\n```', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 48, 'prompt_tokens': 69, 'total_tokens': 117, 'completion_time': 0.061625798, 'prompt_time': 0.00793116, 'queue_time': 0.04803651, 'total_time': 0.069556958}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_90c2e79dab', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--d40d51a6-4f2d-4c05-b843-01353c700ec5-0', usage_metadata={'input_tokens': 69, 'output_tokens': 48, 'total_tokens': 117})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "id": "d36098aa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-29T19:16:41.010546Z",
     "start_time": "2025-09-29T19:16:41.006495Z"
    }
   },
   "source": [
    "print(response.content)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```python\n",
      "import numpy as np\n",
      "import random\n",
      "\n",
      "matrix = np.array([[random.randint(0, 100) for _ in range(3)] for _ in range(3)])\n",
      "print(matrix)\n",
      "print(np.sum(matrix))\n",
      "```\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "id": "39caa649",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-26T09:43:38.060003Z",
     "start_time": "2025-08-26T09:43:35.137036Z"
    }
   },
   "source": [
    "# streaming example\n",
    "import time\n",
    "\n",
    "for token in model.stream(\"hi\"):\n",
    "    time.sleep(0.1)\n",
    "    print(token.content, end=\"|\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|Hi|!| It|'s| nice| to| meet| you|.| Is| there| something| I| can| help| you| with|,| or| would| you| like| to| chat|?||"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "id": "6837d022",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-26T09:43:38.065108Z",
     "start_time": "2025-08-26T09:43:38.063649Z"
    }
   },
   "source": [
    "# Class discussion point: What is an LLM as a program"
   ],
   "outputs": [],
   "execution_count": 12
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mat496-monsoon2025",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
